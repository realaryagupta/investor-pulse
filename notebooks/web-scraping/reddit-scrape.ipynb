{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34c4366-f52e-4b59-9975-d62a368d38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a79e1a-9276-4859-ba7b-4b039a54498b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      2\u001b[39m load_dotenv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f790be08-5965-4b2d-8814-4ff4edd1d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# REDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID')\n",
    "# REDDIT_CLIENT_SECRET = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "# REDDIT_USER_AGENT = os.getenv('REDDIT_USER_AGENT')\n",
    "\n",
    "REDDIT_CLIENT_ID = 'zYdDXB3Ntg3zWzGSZVwNCQ'\n",
    "REDDIT_CLIENT_SECRET = 'JNU1Wx-n9Xy9tZfviPsb_gSA0lB-Gg'\n",
    "REDDIT_USER_AGENT = 'script:reddit_stock_scraper:v1.0 (by /u/AmoebaOld7828)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97526f6a-10cf-4b76-b0bc-edb1a586fb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: None\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id='zYdDXB3Ntg3zWzGSZVwNCQ',\n",
    "    client_secret='JNU1Wx-n9Xy9tZfviPsb_gSA0lB-Gg',\n",
    "    user_agent='script:reddit_stock_scraper:v1.0 (by /u/AmoebaOld7828)'\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Authenticated as:\", reddit.user.me())\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b15387-11d7-4730-b25c-7127bb859cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investing: Should I move some of my NVDA stock to S&P500 or something else? (Score: 7, Comments: 30)\n",
      "investing: AMD, ADI, MPWR or NXPI? Who is going to profit after Nvda? (Score: 1, Comments: 28)\n",
      "wallstreetbets: Screw TSLA, should have gone with NVDA in the first place (Score: 58, Comments: 19)\n",
      "wallstreetbets: Thank You NVDA and META ! Time to diversify and slow down for the summer. What you all regards think ? (Score: 43, Comments: 20)\n",
      "stocks: Is NVIDIA Getting Too Hot? My Short-Term Concerns with NVDA ($141.92) (Score: 13, Comments: 6)\n",
      "stocks: Thinking about picking up some Google, Apple, Broadcom and NVIDIA stock. Thoughts? (Score: 31, Comments: 112)\n"
     ]
    }
   ],
   "source": [
    "subreddits = ['investing', 'wallstreetbets', 'stocks']\n",
    "keywords = ['NVDA', 'AAPL', 'GOOGL', 'AMZN', 'MSFT']\n",
    "\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    for post in subreddit.new(limit=100):\n",
    "        title = post.title.upper()\n",
    "        if any(keyword in title for keyword in keywords):\n",
    "            print(f\"{subreddit_name}: {post.title} (Score: {post.score}, Comments: {post.num_comments})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8472cc0-63ce-4813-af16-31957d288faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import re\n",
    "import datetime\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a28dc0-3d26-47bd-ae58-1ea29291b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping r/investing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/nc9jvld12q115x_g_114k8g40000gn/T/ipykernel_65231/1181834452.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  'created_utc': datetime.datetime.utcfromtimestamp(post.created_utc),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping r/wallstreetbets...\n",
      "Scraping r/stocks...\n"
     ]
    }
   ],
   "source": [
    "# # CONFIGURATION\n",
    "# REDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID')         # or replace with your actual client ID as a string\n",
    "# REDDIT_CLIENT_SECRET = os.getenv('REDDIT_CLIENT_SECRET') # or replace with your actual client secret\n",
    "# REDDIT_USER_AGENT = os.getenv('REDDIT_USER_AGENT')       # or replace with your actual user agent\n",
    "SUBREDDITS = ['investing', 'wallstreetbets', 'stocks']\n",
    "TICKERS = ['GOOGL', 'AAPL', 'MSFT', 'NVDA', 'AMZN']\n",
    "POST_LIMIT = 1000  # per subreddit\n",
    "OUTPUT_FILE = 'reddit_posts.csv'\n",
    "# -----------------------------------\n",
    "\n",
    "reddit = praw.Reddit(client_id=REDDIT_CLIENT_ID,\n",
    "                     client_secret=REDDIT_CLIENT_SECRET,\n",
    "                     user_agent=REDDIT_USER_AGENT)\n",
    "\n",
    "def extract_tickers(text):\n",
    "    found = []\n",
    "    for ticker in TICKERS:\n",
    "        if re.search(r'\\b' + re.escape(ticker) + r'\\b', text.upper()):\n",
    "            found.append(ticker)\n",
    "    return found\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "for sub_name in SUBREDDITS:\n",
    "    print(f\"Scraping r/{sub_name}...\")\n",
    "    subreddit = reddit.subreddit(sub_name)\n",
    "    for post in subreddit.new(limit=POST_LIMIT):\n",
    "        combined_text = (post.title + ' ' + (post.selftext or '')).upper()\n",
    "        tickers_found = extract_tickers(combined_text)\n",
    "        if not tickers_found:\n",
    "            continue  # Skip if no relevant ticker\n",
    "\n",
    "        all_posts.append({\n",
    "            'title': post.title,\n",
    "            'selftext': post.selftext,\n",
    "            'author': str(post.author),\n",
    "            'created_utc': datetime.datetime.utcfromtimestamp(post.created_utc),\n",
    "            'score': post.score,\n",
    "            'subreddit': sub_name,\n",
    "            'tickers_mentioned': ','.join(tickers_found)\n",
    "        })\n",
    "\n",
    "# Write to CSV\n",
    "with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['title', 'selftext', 'author', 'created_utc', 'score', 'subreddit', 'tickers_mentioned']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for post in all_posts:\n",
    "        writer.writerow(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d2a76ca-75b6-4d1f-b5ee-160cd2dea921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved 161 posts to reddit_posts.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_posts)\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\n Saved {len(df)} posts to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24aaa8ea-708e-4baf-b0e1-c9fb319b1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"reddit_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d02d7f9-969d-413e-af3a-08d673172285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>tickers_mentioned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should I move some of my NVDA stock to S&amp;P500 ...</td>\n",
       "      <td>Currently, I have ~$27,000 of NVDA stock. I di...</td>\n",
       "      <td>tortoise2022</td>\n",
       "      <td>2025-06-05 17:34:06</td>\n",
       "      <td>10</td>\n",
       "      <td>investing</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Costco Vs NVidia compare P/E and growth rates</td>\n",
       "      <td>Costco trades at higher PE than NVDA, with low...</td>\n",
       "      <td>Dizzy_Maybe8225</td>\n",
       "      <td>2025-06-05 11:18:02</td>\n",
       "      <td>0</td>\n",
       "      <td>investing</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD, ADI, MPWR or NXPI? Who is going to profit...</td>\n",
       "      <td>Looking at these chip makers trying to compare...</td>\n",
       "      <td>danrennt98</td>\n",
       "      <td>2025-06-04 17:09:53</td>\n",
       "      <td>0</td>\n",
       "      <td>investing</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sold Hood and started positions in Apple, Goog...</td>\n",
       "      <td>Recently I sold all my Hood shares (I got 4300...</td>\n",
       "      <td>coopermug</td>\n",
       "      <td>2025-05-30 01:27:26</td>\n",
       "      <td>0</td>\n",
       "      <td>investing</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semis not recovering despite new wave of AI sp...</td>\n",
       "      <td>Looking at how SMH did recently I can't help t...</td>\n",
       "      <td>SurveyIllustrious738</td>\n",
       "      <td>2025-05-29 07:45:20</td>\n",
       "      <td>6</td>\n",
       "      <td>investing</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Should I move some of my NVDA stock to S&P500 ...   \n",
       "1      Costco Vs NVidia compare P/E and growth rates   \n",
       "2  AMD, ADI, MPWR or NXPI? Who is going to profit...   \n",
       "3  Sold Hood and started positions in Apple, Goog...   \n",
       "4  Semis not recovering despite new wave of AI sp...   \n",
       "\n",
       "                                            selftext                author  \\\n",
       "0  Currently, I have ~$27,000 of NVDA stock. I di...          tortoise2022   \n",
       "1  Costco trades at higher PE than NVDA, with low...       Dizzy_Maybe8225   \n",
       "2  Looking at these chip makers trying to compare...            danrennt98   \n",
       "3  Recently I sold all my Hood shares (I got 4300...             coopermug   \n",
       "4  Looking at how SMH did recently I can't help t...  SurveyIllustrious738   \n",
       "\n",
       "           created_utc  score  subreddit tickers_mentioned  \n",
       "0  2025-06-05 17:34:06     10  investing              NVDA  \n",
       "1  2025-06-05 11:18:02      0  investing              NVDA  \n",
       "2  2025-06-04 17:09:53      0  investing              NVDA  \n",
       "3  2025-05-30 01:27:26      0  investing              NVDA  \n",
       "4  2025-05-29 07:45:20      6  investing              NVDA  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69981af3-e114-469b-b801-05c50e20e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "data['selftext'] = data['selftext'].fillna(\"\")\n",
    "data['created_utc'] = pd.to_datetime(data['created_utc'], errors='coerce')\n",
    "data = data[data['created_utc'].notnull()]\n",
    "data['full_text'] = data['title'] + \" \" + data['selftext']\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'http\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s$]', '', text)  # remove special characters except $\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # normalize whitespace\n",
    "    return text\n",
    "\n",
    "data['clean_text'] = data['full_text'].apply(clean_text)\n",
    "data['author'] = data['author'].str.strip().str.lower()\n",
    "data['subreddit'] = data['subreddit'].str.lower().str.strip()\n",
    "data['tickers_mentioned'] = data['tickers_mentioned'].apply(\n",
    "    lambda x: [t.strip().upper() for t in x.split(',')] if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "data.rename(columns={'created_utc': 'date'}, inplace=True)\n",
    "data.drop_duplicates(subset=['clean_text', 'date', 'author'], inplace=True)\n",
    "data.sort_values('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06d914d5-a3bb-4d1d-9a47-9f768954ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../data/clean-data/reddit-posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476f95f-a882-4bb3-bdbf-70cc19a559d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
